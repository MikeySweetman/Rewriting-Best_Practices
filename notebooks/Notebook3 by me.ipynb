{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5e33d28",
   "metadata": {},
   "source": [
    "# Data Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88dcfb",
   "metadata": {},
   "source": [
    "Here, we will show some simple examples of featurizing materials composition data using so-called \"composition-based feature vectors\", or CBFVs. This methods represents a single chemical formula as one vector based on its constituent atoms' chemical properties (refer to the paper for more information and references).\n",
    "\n",
    "Note that the steps shown in this notebook are intended to demonstrate the best practices associated with featurizing materials data, using *one* way of featurizing materials composition data as an example. \n",
    "Depending on your input data and your particular modeling needs, the data featurization method and procedure you use may be different than the example shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caf705ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "#Set a random seed to ensure reproducibility across runs\n",
    "RNG_SEED = 42 #the answer to ultimate question of life, the universe, and everything\n",
    "np.random.seed(RNG_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e547a",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "\n",
    "We will start with the dataset splits that we saved from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec5d34ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train dataframe shape is (3214, 3)\n",
      "df_val dataframe shape is (980, 3)\n",
      "df_test dataframe shape is (370, 3)\n"
     ]
    }
   ],
   "source": [
    "#getting the paths for all the data\n",
    "PATH = os.getcwd()\n",
    "train_path = os.path.join(PATH, \"../data_for_notebook_bestpractice/cp_train_byme.csv\")\n",
    "val_path = os.path.join(PATH, \"../data_for_notebook_bestpractice/cp_val_byme.csv\")\n",
    "test_path = os.path.join(PATH, \"../data_for_notebook_bestpractice/cp_test_byme.csv\")\n",
    "\n",
    "#now that the paths are created, we can make the dataframes\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "print(\"df_train dataframe shape is\", df_train.shape)\n",
    "print(\"df_val dataframe shape is\", df_val.shape)\n",
    "print(\"df_test dataframe shape is\", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1758dd43",
   "metadata": {},
   "source": [
    "## Sub-sampling your data (optional)\n",
    "\n",
    "If your dataset is too large, you can subsample it to be a smaller size.\n",
    "This is useful for prototyping and for making quick sanity tests of new models / parameters.\n",
    "\n",
    "Just be aware that you do not introduce any bias into your data through the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7c1832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of df_train-sample:(2000, 3)\n",
      "shape of df_val_sample:(200, 3)\n",
      "shape of df_test_sample(200, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train_sample = df_train.sample(n = 2000, random_state = RNG_SEED) #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html\n",
    "df_val_sample = df_val.sample(n = 200, random_state = RNG_SEED)\n",
    "df_test_sample = df_test.sample(n = 200, random_state = RNG_SEED)\n",
    "\n",
    "print(f\"shape of df_train-sample:{df_train_sample.shape}\\nshape of df_val_sample:{df_val_sample.shape}\\nshape of df_test_sample{df_test_sample.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8c122",
   "metadata": {},
   "source": [
    "## Generate features using the `CBFV` package\n",
    "\n",
    "To featurize the chemical compositions from a chemical formula (e.g. \"Al2O3\") into a composition-based feature vector (CBFV), we use the open-source [`CBFV` package](https://github.com/kaaiian/CBFV).\n",
    "\n",
    "We have downloaded and saved a local copy of the package into this repository for your convenience.\n",
    "For the most updated version, refer to the GitHub repository linked above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9ae852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the package and the generate_features function \n",
    "\n",
    "#Import to keep track of what folder this is in!!! not calling from online, it is in the same directory as this code (kinda)\n",
    "from CBFV.cbfv.composition import generate_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9278ed3b",
   "metadata": {},
   "source": [
    "The `generate_features` function from the CBFV package expects an input DataFrame containing at least the columns `['formula', 'target']`. You may also have extra feature columns (e.g., `temperature` or `pressure`, other measurement conditions, etc.).\n",
    "\n",
    "In our dataset, `Cp` represents the target variable, and `T` is the measurement condition.\n",
    "Since the `generate_features` function expects the target variable column to be named `target`, we have to rename the `Cp` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff4f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame column names before renaming:\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "Index(['formula', 'T', 'Cp'], dtype='object')\n",
      "\n",
      "DataFrame column names after renaming:\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n",
      "Index(['formula', 'T', 'target'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('DataFrame column names before renaming:')\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)\n",
    "\n",
    "#renaming Cp column to \"target\"\n",
    "rename_cp = {\"Cp\" : \"target\"} #this is a dictionary\n",
    "df_train = df_train.rename(columns = rename_cp) #finds key \"Cp\" and replaces its value with \"target\"\n",
    "df_val = df_val.rename(columns = rename_cp)\n",
    "df_test = df_test.rename(columns = rename_cp)\n",
    "\n",
    "df_train_sample = df_train_sample.rename(columns = rename_cp)\n",
    "df_val_sample = df_val_sample.rename(columns = rename_cp)\n",
    "df_test_sample = df_test_sample.rename(columns = rename_cp)\n",
    "\n",
    "print('\\nDataFrame column names after renaming:')\n",
    "print(df_train.columns)\n",
    "print(df_val.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1361ef3",
   "metadata": {},
   "source": [
    "Now we can use the `generate_features` function to generate the CBFVs from the input data.\n",
    "\n",
    "Note that we have specified several keyword arguments in our call to `generate_features`:\n",
    "* `elem_prop='oliynyk'`\n",
    "* `drop_duplicates=False`\n",
    "* `extend_features=True`\n",
    "* `sum_feat=True`\n",
    "\n",
    "A short explanation for the choice of keyword arguments is below:\n",
    "* The `elem_prop` parameter specifies which CBFV featurization scheme to use (there are several). For this tutorial, we have chosen to use the `oliynyk` CBFV featurization scheme.\n",
    "* The `drop_duplicates` parameter specifies whether to drop duplicate formulae during featurization. In our case, we want to preserve duplicate formulae in our data (`True`), since we have multiple heat capacity measurements (performed at different temperatures) for the same compound.\n",
    "* The `extend_features` parameter specifies whether to include extended features (features that are not part of `['formula', 'target']`) in the featurized data. In our case, this is our measurement temperature, and we want to include this information (`True`), since this is pertinent information for the heat capacity prediction.\n",
    "* The `sum_feat` parameter specifies whether to calculate the sum features when generating the CBFVs for the chemical formulae. We do in our case (`True`).\n",
    "\n",
    "For more information about the `generate_features` function and the CBFV featurization scheme, refer to the GitHub repository and the accompanying paper to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9598e545",
   "metadata": {},
   "source": [
    "# need to play around with this generate features function\n",
    "# probably in a new notebook \n",
    "# just want a feel of what its inputs, outputs, etc are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9971e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 23517.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|████████████████████████████████████████████████████| 2000/2000 [00:00<00:00, 12668.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████████████████████████████████████████████████| 200/200 [00:00<00:00, 18182.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|██████████████████████████████████████████████████████| 200/200 [00:00<00:00, 12502.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Input Data: 100%|██████████████████████████████████████████████████████| 200/200 [00:00<00:00, 25011.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tFeaturizing Compositions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning Features...: 100%|███████████████████████████████████████████████████████| 200/200 [00:00<00:00, 9525.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCreating Pandas Objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#note that what is labelled here is unscaled!!!\n",
    "X_train_unscaled, y_train, formulae_train, skipped_train = generate_features(df_train_sample, elem_prop = 'oliynyk', drop_duplicates = False, extend_features = True, sum_feat = True)\n",
    "X_val_unscaled, y_val, formulae_val, skipped_val = generate_features(df_val_sample, elem_prop = 'oliynyk', drop_duplicates = False, extend_features = True, sum_feat = True)\n",
    "X_test_unscaled, y_test, formulae_test, skipped_test = generate_features(df_test_sample, elem_prop = 'oliynyk', drop_duplicates = False, extend_features = True, sum_feat = True)\n",
    "\n",
    "#outputs feature dfs for train val and test\n",
    "#x involves input data (here it is temp and Cp)\n",
    "#y_train is the corresponding \"target\" values for the X_train__unscaled\n",
    "#formulae train is df of the chemical formulaes for the corresponding indexes\n",
    "#eg sumatomicnumber for index 0 of x_train is 32, chemical formula is given in formula train ()\n",
    "\n",
    "#I think drop_duplicates will remove a formula if seen more than once i.e. only keep first example of it\n",
    "#for Cp there will be same formula at many different temps so we don't want to get rid of duplicates\n",
    "#therefore it is set to false\n",
    "\n",
    "#dunno what skipped_train is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ed19e",
   "metadata": {},
   "source": [
    "To see what a featurized X matrix looks like, `.head()` will show us some rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813f7ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_Atomic_Number</th>\n",
       "      <th>sum_Atomic_Weight</th>\n",
       "      <th>sum_Period</th>\n",
       "      <th>sum_group</th>\n",
       "      <th>sum_families</th>\n",
       "      <th>sum_Metal</th>\n",
       "      <th>sum_Nonmetal</th>\n",
       "      <th>sum_Metalliod</th>\n",
       "      <th>sum_Mendeleev_Number</th>\n",
       "      <th>sum_l_quantum_number</th>\n",
       "      <th>...</th>\n",
       "      <th>range_Melting_point_(K)</th>\n",
       "      <th>range_Boiling_Point_(K)</th>\n",
       "      <th>range_Density_(g/mL)</th>\n",
       "      <th>range_specific_heat_(J/g_K)_</th>\n",
       "      <th>range_heat_of_fusion_(kJ/mol)_</th>\n",
       "      <th>range_heat_of_vaporization_(kJ/mol)_</th>\n",
       "      <th>range_thermal_conductivity_(W/(m_K))_</th>\n",
       "      <th>range_heat_atomization(kJ/mol)</th>\n",
       "      <th>range_Cohesive_energy</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>65.116040</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.642621e+06</td>\n",
       "      <td>4.742507e+06</td>\n",
       "      <td>0.858492</td>\n",
       "      <td>0.021622</td>\n",
       "      <td>2388.183171</td>\n",
       "      <td>22965.815879</td>\n",
       "      <td>3091.366423</td>\n",
       "      <td>66594.888889</td>\n",
       "      <td>7.034755</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.0</td>\n",
       "      <td>53.491200</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.363940e+03</td>\n",
       "      <td>8.544527e+03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>40.816697</td>\n",
       "      <td>1.696930</td>\n",
       "      <td>17.270367</td>\n",
       "      <td>0.006030</td>\n",
       "      <td>22037.555556</td>\n",
       "      <td>4.284089</td>\n",
       "      <td>457.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>98.887792</td>\n",
       "      <td>14.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.009057e+05</td>\n",
       "      <td>1.662798e+06</td>\n",
       "      <td>0.601941</td>\n",
       "      <td>1.321867</td>\n",
       "      <td>10.138486</td>\n",
       "      <td>13933.526946</td>\n",
       "      <td>6716.921700</td>\n",
       "      <td>10368.666667</td>\n",
       "      <td>1.070067</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>41.988171</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.521744e+04</td>\n",
       "      <td>2.868138e+05</td>\n",
       "      <td>0.234886</td>\n",
       "      <td>0.042025</td>\n",
       "      <td>1.372178</td>\n",
       "      <td>2194.463394</td>\n",
       "      <td>4968.283245</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.0</td>\n",
       "      <td>207.200000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum_Atomic_Number  sum_Atomic_Weight  sum_Period  sum_group  sum_families  \\\n",
       "0               32.0          65.116040         8.0       30.0          15.0   \n",
       "1               28.0          53.491200         9.0       36.0          43.0   \n",
       "2               46.0          98.887792        14.0       72.0          36.0   \n",
       "3               20.0          41.988171         5.0       18.0           9.0   \n",
       "4               82.0         207.200000         6.0       14.0           5.0   \n",
       "\n",
       "   sum_Metal  sum_Nonmetal  sum_Metalliod  sum_Mendeleev_Number  \\\n",
       "0        1.0           2.0            0.0                 162.0   \n",
       "1        0.0           6.0            0.0                 544.0   \n",
       "2        3.0           4.0            0.0                 441.0   \n",
       "3        1.0           1.0            0.0                  95.0   \n",
       "4        1.0           0.0            0.0                  81.0   \n",
       "\n",
       "   sum_l_quantum_number  ...  range_Melting_point_(K)  \\\n",
       "0                   2.0  ...             2.642621e+06   \n",
       "1                   2.0  ...             4.363940e+03   \n",
       "2                   4.0  ...             4.009057e+05   \n",
       "3                   1.0  ...             2.521744e+04   \n",
       "4                   1.0  ...             0.000000e+00   \n",
       "\n",
       "   range_Boiling_Point_(K)  range_Density_(g/mL)  \\\n",
       "0             4.742507e+06              0.858492   \n",
       "1             8.544527e+03              0.000002   \n",
       "2             1.662798e+06              0.601941   \n",
       "3             2.868138e+05              0.234886   \n",
       "4             0.000000e+00              0.000000   \n",
       "\n",
       "   range_specific_heat_(J/g_K)_  range_heat_of_fusion_(kJ/mol)_  \\\n",
       "0                      0.021622                     2388.183171   \n",
       "1                     40.816697                        1.696930   \n",
       "2                      1.321867                       10.138486   \n",
       "3                      0.042025                        1.372178   \n",
       "4                      0.000000                        0.000000   \n",
       "\n",
       "   range_heat_of_vaporization_(kJ/mol)_  \\\n",
       "0                          22965.815879   \n",
       "1                             17.270367   \n",
       "2                          13933.526946   \n",
       "3                           2194.463394   \n",
       "4                              0.000000   \n",
       "\n",
       "   range_thermal_conductivity_(W/(m_K))_  range_heat_atomization(kJ/mol)  \\\n",
       "0                            3091.366423                    66594.888889   \n",
       "1                               0.006030                    22037.555556   \n",
       "2                            6716.921700                    10368.666667   \n",
       "3                            4968.283245                      225.000000   \n",
       "4                               0.000000                        0.000000   \n",
       "\n",
       "   range_Cohesive_energy       T  \n",
       "0               7.034755   600.0  \n",
       "1               4.284089   457.7  \n",
       "2               1.070067   300.0  \n",
       "3               0.018632  2800.0  \n",
       "4               0.000000  1400.0  \n",
       "\n",
       "[5 rows x 177 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unscaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155a70c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 177)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_unscaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da18ba4",
   "metadata": {},
   "source": [
    "Note the `sum` features in the CBFV, which we have included by using `sum_feat=True` in the call to `generate_features`.\n",
    "\n",
    "Also note the temperature column `T` at the end of this featurized data.\n",
    "\n",
    "What we have done above is featurize the input data. In the featurized data, each row contains a unique CBFV that describes a given chemical composition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b77ce",
   "metadata": {},
   "source": [
    "## Data scaling & normalization\n",
    "\n",
    "For numerical input data, scaling and normalization of the features often improves the model performance.\n",
    "Scaling can partially correct the discrepancy between the orders of magnitudes of the features (e.g., some numerical features being much larger or smaller than others).\n",
    "This typically improves the model learning performance, and in turn, improves the model performance.\n",
    "\n",
    "We will scale then normalize our input data using scikit-learn's built-in `StandardScaler` class and `normalize` function.\n",
    "\n",
    "Note, in addition to `StandardScaler`, other scalers such as `RobustScaler` and `MinMaxScaler` are also available in scikit-learn. Consult the documentation for the details and when to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd0f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9960d55a",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "\n",
    "First, we instantiate the scaler object.\n",
    "\n",
    "In a `StandardScaler` object:\n",
    "* During the `fit` process, the statistics of the input data (mean and standard deviation) are computed.\n",
    "* Then, during the `transform` process, the mean and standard deviation values calculated above are used to scale the data to having zero-mean and unit variance.\n",
    "\n",
    "Therefore, for the first time usage of the scaler, we call the `.fit_transform()` method to fit the scaler to the input data, and then to transform the same data.\n",
    "For subsequent uses, since we have already computed the statistics, we only call the `.transform()` method to scale data.\n",
    "\n",
    "# **Note:** you should *only* `.fit()` the scaler using the training dataset statistics, and then use these same statistics from the training dataset to `.transform()` the other datasets (validation and train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81288b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always scale first and then normalise!!!\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_unscaled) #calculated mean and standard dev, scales to 0 mean and sigma = 1\n",
    "X_val = scaler.transform(X_val_unscaled)         #scales the val and test, from stats found in train (scalar.fit())\n",
    "X_test = scaler.transform(X_test_unscaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41323e5c",
   "metadata": {},
   "source": [
    "## Normalizing the scaled data\n",
    "\n",
    "We repeat a similar process for normalizing the data.\n",
    "Here, there is no need to first fit the normalizer, since the normalizer scales the rows of the input data to unit norm independently of other rows.\n",
    "\n",
    "The normalizer is different to a Scaler in that the normalizer acts row-wise, whereas a Scaler acts column-wise on the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9544b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I need to look into scaling vs normalising more\n",
    "#Possibly plot histogram of some data I have and see how it changes before and after scaling/normalisation\n",
    "X_train = normalize(X_train)\n",
    "X_val = normalize(X_val)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13759c1f",
   "metadata": {},
   "source": [
    "# Modeling using \"classical\" machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51982192",
   "metadata": {},
   "source": [
    "Here we implement some classical ML models from `sklearn`:\n",
    "\n",
    "* Ridge regression\n",
    "* Support vector machine\n",
    "* Linear support vector machine\n",
    "* Random forest\n",
    "* Extra trees\n",
    "* Adaptive boosting\n",
    "* Gradient boosting\n",
    "* k-nearest neighbors\n",
    "* Dummy (if you can't beat this, something is wrong.)\n",
    "\n",
    "Note: the Dummy model types from `sklearn` act as a good sanity check for your ML studies. If your models do not perform significantly better than the equivalent Dummy models, then you should know that something has gone wrong in your model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bee7fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57225751",
   "metadata": {},
   "source": [
    "In addition, we define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23fb7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_model(model_name):  #model_name is callable, putting the () calls model_name\n",
    "    model = model_name()       #assigns class \"model_name()\" to varianle \"model\"  \n",
    "    return model               #this is because the name of a model is part of its class\n",
    "                               #i.e the name of a model is an integral attribute of the model\n",
    "                               #need to learn more about classes, objects, etc\n",
    "\n",
    "\n",
    "def fit_model(model, X_train, y_train): #input is the model, input, and train output\n",
    "    ti = time()\n",
    "    model = instantiate_model(model)    #sets model to model_name(), eg if using SVR\n",
    "    model.fit(X_train, y_train)         #uses model.fit() instead of SVR.fit()\n",
    "    fit_time = time() - ti              #this means it can be iterated easier\n",
    "    return model, fit_time              #returns model (which is the model name) and the time it took to fit it\n",
    "                                        #this basically trains the model\n",
    "\n",
    "\n",
    "def evaluate_model(model, X, y_act): #this gets a prediction from already trained model, then compares to actual data\n",
    "    y_pred = model.predict(X)        \n",
    "    r2 = r2_score(y_act, y_pred)\n",
    "    mae = mean_absolute_error(y_act, y_pred)\n",
    "    rmse_val = mean_squared_error(y_act, y_pred, squared=False)\n",
    "    return r2, mae, rmse_val\n",
    "\n",
    "\n",
    "def fit_evaluate_model(model, model_name, X_train, y_train, X_val, y_act_val): #fits (trains) model\n",
    "    model, fit_time = fit_model(model, X_train, y_train)                       #then evaluates on train and val data\n",
    "    r2_train, mae_train, rmse_train = evaluate_model(model, X_train, y_train) \n",
    "    r2_val, mae_val, rmse_val = evaluate_model(model, X_val, y_act_val) \n",
    "    result_dict = {                                                      \n",
    "        'model_name': model_name,\n",
    "        'model_name_pretty': type(model).__name__,            #creates a dictionary\n",
    "        'model_params': model.get_params(),                   #this is in the form \"name of thing\" : \"value of thing\"\n",
    "        'fit_time': fit_time,                                 #can then be iterated to create dataframe\n",
    "        'r2_train': r2_train,                                 #then retuns (\"model?\") and the dictionary\n",
    "        'mae_train': mae_train,                               #this is basically one row of a dataframe\n",
    "        'rmse_train': rmse_train,                             \n",
    "        'r2_val': r2_val,\n",
    "        'mae_val': mae_val,\n",
    "        'rmse_val': rmse_val}\n",
    "    return model, result_dict\n",
    "\n",
    "\n",
    "def append_result_df(df, result_dict):  #creates df from dictionary, then returns it\n",
    "    df_result_appended = df.append(result_dict, ignore_index = True) #ignore index means rows not numbered\n",
    "    return df_result_appended                #basically adds the evaluation from a model onto this df when iterating\n",
    "                                             #important that you don't keep appendening to the same df with data you need \n",
    "                                             #already in it ***\n",
    "\n",
    "\n",
    "\n",
    "def append_model_dict(dic, model_name, model): #creates list of model names\n",
    "    dic[model_name] = model                    #with the way its set up each input is a tuple as it come from a dictionary\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851debc5",
   "metadata": {},
   "source": [
    "Build an empty DataFrame to store model results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dde44fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_name_pretty</th>\n",
       "      <th>model_params</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>r2_train</th>\n",
       "      <th>mae_train</th>\n",
       "      <th>rmse_train</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>mae_val</th>\n",
       "      <th>rmse_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, model_name_pretty, model_params, fit_time, r2_train, mae_train, rmse_train, r2_val, mae_val, rmse_val]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a data frame and labelling columns\n",
    "df_classics = pd.DataFrame(columns=['model_name',\n",
    "                                    'model_name_pretty',\n",
    "                                    'model_params',\n",
    "                                    'fit_time',\n",
    "                                    'r2_train',\n",
    "                                    'mae_train',\n",
    "                                    'rmse_train',\n",
    "                                    'r2_val',\n",
    "                                    'mae_val',\n",
    "                                    'rmse_val'])\n",
    "df_classics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d56c8b",
   "metadata": {},
   "source": [
    "## Define the models\n",
    "\n",
    "Here, we instantiate several classical machine learning models for use.\n",
    "For demonstration purposes, we instantiate the models with their default model parameters.\n",
    "\n",
    "Some of the models listed above can perform either regression or classification tasks.\n",
    "Because our ML task is a regression task (prediction of the continuous-valued target, heat capacity), we choose the regression variant of these models.\n",
    "\n",
    "Note: the `DummyRegressor()` instance acts as a good sanity check for your ML studies. If your models do not perform significantly better than the `DummyRegressor()`, then you know something has gone awry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9df583ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('dumr', <class 'sklearn.dummy.DummyRegressor'>), ('rr', <class 'sklearn.linear_model._ridge.Ridge'>), ('abr', <class 'sklearn.ensemble._weight_boosting.AdaBoostRegressor'>), ('gbr', <class 'sklearn.ensemble._gb.GradientBoostingRegressor'>), ('rfr', <class 'sklearn.ensemble._forest.RandomForestRegressor'>), ('etr', <class 'sklearn.ensemble._forest.ExtraTreesRegressor'>), ('svr', <class 'sklearn.svm._classes.SVR'>), ('lsvr', <class 'sklearn.svm._classes.LinearSVR'>), ('knr', <class 'sklearn.neighbors._regression.KNeighborsRegressor'>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build a dictionary of model names\n",
    "classic_model_names = OrderedDict({ #OrderedDict preserves the order in which the keys are inserted \n",
    "    'dumr': DummyRegressor,         #A regular dict doesn’t track the insertion order and iterating\n",
    "    'rr': Ridge,                    # it gives the values in an arbitrary order\n",
    "    'abr': AdaBoostRegressor,\n",
    "    'gbr': GradientBoostingRegressor,\n",
    "    'rfr': RandomForestRegressor,\n",
    "    'etr': ExtraTreesRegressor,\n",
    "    'svr': SVR,\n",
    "    'lsvr': LinearSVR,\n",
    "    'knr': KNeighborsRegressor,\n",
    "})\n",
    "\n",
    "classic_model_names.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6f0c6",
   "metadata": {},
   "source": [
    "## Instantiate and fit the models\n",
    "\n",
    "Now, we can fit the ML models.\n",
    "\n",
    "We will loop through each of the models listed above. For each of the models, we will:\n",
    "* instantiate the model (with default parameters)\n",
    "* fit the model using the training data\n",
    "* use the fitted model to generate predictions from the validation data\n",
    "* evaluate the performance of the model using the predictions\n",
    "* store the results in a DataFrame for analysis\n",
    "\n",
    "Note: this may take several minutes, depending on your hardware/software environment, dataset size and featurization scheme (CBFV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e316cb14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now fitting model dumr : DummyRegressor\n",
      "Now fitting model rr : Ridge\n",
      "Now fitting model abr : AdaBoostRegressor\n",
      "Now fitting model gbr : GradientBoostingRegressor\n",
      "Now fitting model rfr : RandomForestRegressor\n",
      "Now fitting model etr : ExtraTreesRegressor\n",
      "Now fitting model svr : SVR\n",
      "Now fitting model lsvr : LinearSVR\n",
      "Now fitting model knr : KNeighborsRegressor\n",
      "\n",
      "Finished fitting 9 \n",
      " 27.241197109222412 seconds taken\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#***here I got confused because shape of df was bigger than should've been, this is because I ran\n",
    "#this block of code multiple times without cleaning df_classics\n",
    "\n",
    "#Instantiate a dictionary to store the model objects\n",
    "classic_models = OrderedDict()\n",
    "\n",
    "# Keep track of elapsed time\n",
    "ti = time()\n",
    "\n",
    "#google for x,y in python if looking back at this\n",
    "#creating a loop to fit each model and then store the results\n",
    "#.items() returns dictionary to tuple\n",
    "#in this specific case it returns it as(model_name, model)\n",
    "#this means you are iterating through tuples not integers or something\n",
    "#so the in between \"for\" and \"in\" you need both the model_name, model to be placed there\n",
    "for model_name, model in classic_model_names.items(): \n",
    "   \n",
    "    print(\"Now fitting model\", model_name, \":\", model.__name__)\n",
    "    \n",
    "    model, result_dict = fit_evaluate_model(model, model_name, X_train, y_train, X_val, y_val) #defined above\n",
    "    #this gives what model is being used and returns dictionary of results\n",
    "    \n",
    "    df_classics = append_result_df(df_classics, result_dict) #add results_dict to  df_classics\n",
    "    #print(f\"\\n\\ndf_classics is\\n{df_classics}\\n\\n\")\n",
    "    \n",
    "    classic_models = append_model_dict(classic_models, model_name, model) #not sure\n",
    "    #print(f\"classic_models is {classic_models}\\n\")\n",
    "    \n",
    "dt = time() - ti\n",
    "\n",
    "print(\"\\nFinished fitting\", len(classic_models), \"\\n\", dt, \"seconds taken\") #using the f sting thing is probably better idk\n",
    "\n",
    "\n",
    "df_classics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16639fee",
   "metadata": {},
   "source": [
    "Now, we can look at the results.\n",
    "\n",
    "You will notice, that some of the models (such as RandomForestRegressor, ExtraTreesRegressor and GradientBoostingRegressor) have completely memorized the training data, as evidenced by the very high r2_train scores of ~1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3830d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort in order of increasing validation r2 score\n",
    "df_classics = df_classics.sort_values('r2_val', ignore_index = True) #don't want rows labelled so set to true\n",
    "df_classics                                                          #although nothing seems to change when it's False?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c91e7",
   "metadata": {},
   "source": [
    "You can now also access the full details of the models by inspecting the `classic_models` dictionary that we populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8068082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759c4c6",
   "metadata": {},
   "source": [
    "## Evaluating model performance on validation dataset\n",
    "\n",
    "Now comes the time to evaluate the trained models on the validation set.\n",
    "\n",
    "Remember, we use the same validation set to evaluate all models. This ensures a fair comparison.\n",
    "\n",
    "In addition, we plot the predicted vs. actual plots using the predictions made by each trained model on the same validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D.set_markeredgecolor\n",
    "\n",
    "#input is actual values, predicted values, model used, regline is set to true automatically, label is a string\n",
    "def plot_pred_act(actual, predicted, model, reg_line = True, label = \"\"):\n",
    "    xy_max = np.max([np.max(actual), np.max(predicted)])\n",
    "    \n",
    "    plot = plt.figure(figsize = (6,6)) #plt.figure() makes an object explicitly, it can be maipulated then later\n",
    "    plt.plot(actual, predicted, 'o', ms = 9, mec = 'k', mfc = 'pink', alpha = 0.4) \n",
    "        #o is circle marker, msis markersize, mec is marker edge colour, mfc is marker face colour                          \n",
    "        #alpha is opacity\n",
    "    plt.plot([0, xy_max], [0, xy_max], 'k--', label='ideal') #creates ideal line from bleft to tright of square\n",
    "    \n",
    "    #below gives regression line for the predicted data\n",
    "    if reg_line: #shorthand for \"if reg_line == True:\"\n",
    "        polyfit = np.polyfit(actual, predicted, deg = 1) #least squares polynomial fit, deg = 1 for linear line\n",
    "                                                 #returns [x coeffcient     y intercept]\n",
    "        #np.poly1d([1,2,3]) == (x-1)(x-2)(x-3)\n",
    "        #not sure why finding unique values, presume it's so not several markers for same point\n",
    "        reg_ys = np.poly1d(polyfit)(np.unique(actual)) #DONT UNDERSTAND THIS ONE\n",
    "        plt.plot(np.unique(actual), reg_ys, alpha=0.8, label='linear fit') #plots reg line\n",
    "     \n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.xlabel(\"Actual\" + label) #label is a string so need to use + not ,\n",
    "    plt.ylabel(\"Predicted\" + label)\n",
    "    \n",
    "    plt.title(f'{type(model).__name__}, r2: {r2_score(actual, predicted)}')\n",
    "    #plt.title(type(model).__name__ ,\"r2:\", r2_score(actual,predicted)) #can' get this to not give errors\n",
    "    \n",
    "    plt.legend(loc = \"best\")\n",
    "    \n",
    "    #screwing around with background colours\n",
    "    #ax = plt.gca()\n",
    "    #ax.set_facecolor(\"yellow\")\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#row goes from 0 to no. of rows in df_classics\n",
    "for row in range(df_classics.shape[0]):\n",
    "    model_name = df_classics.iloc[row]['model_name'] #using iloc[] because row is an integer not a label\n",
    "\n",
    "    model = classic_models[model_name]\n",
    "    y_act_val = y_val\n",
    "    y_pred_val = model.predict(X_val)\n",
    "\n",
    "    plot = plot_pred_act(y_act_val, y_pred_val, model, label='$\\mathrm{C}_\\mathrm{p}$ (J / mol K)') #dunno about the label fam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca736b",
   "metadata": {},
   "source": [
    "## Re-training the best-performing model on combined train + validation dataset\n",
    "\n",
    "After you have finalized your model, you can re-train your model (using the same hyperparameters) again on the combined train + validation datasets, and finally, evaluate your model on the held-out test dataset.\n",
    "\n",
    "By training on the combined train + validation dataset after you have finished tuning your model, you give it more training data, which should lead to an increase in the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bf8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually getting the best-performing model that we have tested\n",
    "best_row = df_classics.iloc[-1, :].copy()\n",
    "\n",
    "#Get the model type and model parameters\n",
    "model_name = best_row['model_name']\n",
    "model_params = best_row['model_params']\n",
    "\n",
    "#Instantiate the model again using the parameters\n",
    "#putting (**model_params) replaces default parameters with ones already used I THINK DONT ACTUALLY KNOW\n",
    "model = classic_model_names[model_name](**model_params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ec1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the train and validation datasets together\n",
    "X_train_new = np.concatenate((X_train, X_val), axis = 0) #these are arrays so np.concatenate()\n",
    "y_train_new = pd.concat((y_train, y_val), axis = 0)      #these are dataframes so pd.concat()\n",
    "\n",
    "print(X_train_new.shape)\n",
    "print(y_train_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2508f",
   "metadata": {},
   "source": [
    "Finally, we can fit the model on the combined train + validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7028ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = time()\n",
    "\n",
    "model.fit(X_train_new, y_train_new)\n",
    "\n",
    "dt = time() - ti \n",
    "\n",
    "print(\"Finished fitting best model, total time:\", dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07304a81",
   "metadata": {},
   "source": [
    "## Testing the re-trained model on the test dataset\n",
    "\n",
    "After re-fitting the best model on the train+validation dataset, you can finally test it on the test dataset.\n",
    "**Remember:** you should only do this *once!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b47edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe need to be a bit more clear on where y test, ypredtest, etc come from and what happens to test inputs\n",
    "\n",
    "y_act_test = y_test\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "r2, mae, rmse = evaluate_model(model, X_test, y_test)\n",
    "print(\"r2:\", r2)\n",
    "print(\"mae\", mae)\n",
    "print(\"rmse\", rmse)\n",
    "\n",
    "plot = plot_pred_act(y_act_test, y_pred_test, model, label='$\\mathrm{C}_\\mathrm{p}$ (J / mol K)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6569a5",
   "metadata": {},
   "source": [
    "We see that our model achieves decent performance on the held-out test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f66bd6",
   "metadata": {},
   "source": [
    "# Effect of train/validation/test dataset split\n",
    "\n",
    "Using different train/validation/test splits can dramatically affect your model performance, even for classical ML models.\n",
    "\n",
    "Here, we provide a little demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating same features as above, just doing it again as data has been manipulated\n",
    "X_train_unscaled, y_train, formulae_train, skipped_train = generate_features(df_train, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_val_unscaled, y_val, formulae_val, skipped_val = generate_features(df_val, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)\n",
    "X_test_unscaled, y_test, formulae_test, skipped_test = generate_features(df_test, elem_prop='oliynyk', drop_duplicates=False, extend_features=True, sum_feat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train_unscaled.copy()\n",
    "X_val = X_val_unscaled.copy()\n",
    "X_test = X_test_unscaled.copy()\n",
    "\n",
    "y_train_original = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b71ca",
   "metadata": {},
   "source": [
    "We sample the training data using 10 random seeds, by using the `DataFrame.sample()` method with seeds ranging from 0 to 9.\n",
    "We then fit 10 models, each on one of the random splits, and evaluate their performance on the same validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ea941",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = range(10)\n",
    "df_splits = pd.DataFrame(columns=['split',\n",
    "                                  'r2_train',\n",
    "                                  'mae_train',\n",
    "                                  'rmse_train',\n",
    "                                  'r2_val',\n",
    "                                  'mae_val',\n",
    "                                  'rmse_val'])\n",
    "\n",
    "for split_no in splits:\n",
    "    print(\"Fitting and evaluating random split\", split_no)\n",
    "    #now I need to sample the data, standerise, normalise, fit and evaluate\n",
    "    \n",
    "    #sampling\n",
    "    X_train = X_train_original.sample(frac = 0.7, random_state = split_no) #random_state is seed for pseudorandom numbers\n",
    "    y_train = y_train_original[X_train.index] #this finds the corresponding y value at the correct index (same index as X)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = normalize(scaler.fit_transform(X_train))  #normalising and scaling in the one line\n",
    "    X_val = normalize(scaler.transform(X_val_unscaled)) #note just .transform() here, not .fit()\n",
    "    X_test = normalize(scaler.transform(X_test_unscaled))\n",
    "    \n",
    "    model = AdaBoostRegressor() #dunno why using this one, might mess around with this one\n",
    "    model.fit(X_train, y_train) #training model on this split\n",
    "    y_act_val = y_val\n",
    "    y_pred_val = model.predict(X_val) #now predicting the trained model on the validation data\n",
    "    \n",
    "    r2_train, mae_train, rmse_train = evaluate_model(model, X_train, y_train)\n",
    "    r2_val, mae_val, rmse_val = evaluate_model(model, X_val, y_val)\n",
    "    result_dict = {\n",
    "        'split': split_no,\n",
    "        'r2_train': r2_train,\n",
    "        'mae_train': mae_train,\n",
    "        'rmse_train': rmse_train,\n",
    "        'r2_val': r2_val,\n",
    "        'mae_val': mae_val,\n",
    "        'rmse_val': rmse_val}\n",
    "    \n",
    "    df_splits = append_result_df(df_splits, result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits['split'] = df_splits['split'].astype(int) #split numbers are floats instead of ints, so turning them into ints\n",
    "df_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7486571",
   "metadata": {},
   "source": [
    "We then plot the train and validation $r^2$ scores for each of the 10 models.\n",
    "\n",
    "Note the high variability in the r2_val score. In contrast, the variability in the r2_train score is comparatively lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deae861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.plot makes plots of Series or DataFrame\n",
    "df_splits.plot('split', ['r2_train', 'r2_val'], kind = 'bar') \n",
    "#first x values. In this case it is split number\n",
    "#['r2_train', 'r2_val'] are the y values for each x\n",
    "#kind is bar, line, boxplot, etc\n",
    "plt.title(f'Performance of {type(model).__name__}\\nwith {len(splits)} different data splits') #not arsed rewriting this\n",
    "plt.ylim((0.5, 1.0))\n",
    "plt.ylabel('$r^2$')\n",
    "plt.xlabel('Split #')\n",
    "plt.legend(loc = 'lower right', framealpha = 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614334c",
   "metadata": {},
   "source": [
    "This effect is even more pronounced when we plot the mean abolute error (MAE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235ab045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above just mae not r2\n",
    "df_splits.plot('split', ['mae_train', 'mae_val'], kind='bar')\n",
    "plt.title(f'Performance of {type(model).__name__}\\nwith {len(splits)} different data splits')\n",
    "plt.ylabel('MAE in $\\mathrm{C}_\\mathrm{p}$ (J / mol K)')\n",
    "plt.xlabel('Split #')\n",
    "plt.legend(loc='lower right', framealpha=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a3cc06",
   "metadata": {},
   "source": [
    "Therefore, typically the average value of all the scores are reported, as this gives a much more accurate estimate of how well the model actually performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5722c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_r2_val = df_splits['r2_val'].mean()\n",
    "avg_mae_val = df_splits['mae_val'].mean()\n",
    "\n",
    "print(\"Average validation r2 is\", avg_r2_val)\n",
    "print(\"Average validation mae is\", avg_r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e1555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
